{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sql\n",
    "from pyspark import SparkContext\n",
    "\n",
    "#from pyspark.sql.SQLContext import createDataFrame\n",
    "#from pyspark.sql.SparkSession import createDataFrame\n",
    "from pyspark.sql import SparkSession, SQLContext,        #class\n",
    "\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create departments\n",
    "department1 = sql.Row(id = '123456', name='CS')\n",
    "department2 = sql.Row(id = '789012', name='ME')\n",
    "department3 = sql.Row(id = '234567', name='MM')\n",
    "department4 = sql.Row(id = '456789', name='EE')\n",
    "# Employee\n",
    "Employee = sql.Row('firstName', 'lastName', 'email', 'salary')\n",
    "employee1 = Employee('erxiao','wang', 'xxx@berkekey.edu', 100000)\n",
    "employee2 = Employee('jh','wang', 'xxxx@standord.edu', 120000)\n",
    "employee3 = Employee('tim', None, 'xxxx@cit.edu', 140000)\n",
    "employee4 = Employee(None,'ng', 'xxxx@mit.edu', 160000)\n",
    "# combine department and employee\n",
    "departmentWithemployee1 = sql.Row(department = department1, employees =[employee1, employee2])\n",
    "departmentWithemployee2 = sql.Row(department = department2, employees = [employee3, employee4])\n",
    "departmentWithemployee3 = sql.Row(department = department3, employees = [employee1, employee4])\n",
    "departmentWithemployee4 = sql.Row(department = department4, employees = [employee2, employee3])\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlConctent = SQLContext(sc)\n",
    "sparkSession = SparkSession(sc)\n",
    "df1 = sqlConctent.createDataFrame([departmentWithemployee1, departmentWithemployee2])\n",
    "df2 = sparkSession.createDataFrame([departmentWithemployee2, departmentWithemployee4])\n",
    "df3 = sqlConctent.createDataFrame([departmentWithemployee3, departmentWithemployee4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print pyspark df object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(department=Row(id='123456', name='CS'), employees=[Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000), Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000)]),\n",
       " Row(department=Row(id='789012', name='ME'), employees=[Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000), Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000)])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[department: struct<id:string,name:string>, employees: array<struct<firstName:string,lastName:string,email:string,salary:bigint>>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(123456, CS)</td>\n",
       "      <td>[(erxiao, wang, xxx@berkekey.edu, 100000), (jh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(789012, ME)</td>\n",
       "      <td>[(tim, None, xxxx@cit.edu, 140000), (None, ng,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     department                                          employees\n",
       "0  (123456, CS)  [(erxiao, wang, xxx@berkekey.edu, 100000), (jh...\n",
       "1  (789012, ME)  [(tim, None, xxxx@cit.edu, 140000), (None, ng,..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## union DF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(department=Row(id='123456', name='CS'), employees=[Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000), Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000)]),\n",
       " Row(department=Row(id='789012', name='ME'), employees=[Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000), Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000)]),\n",
       " Row(department=Row(id='234567', name='MM'), employees=[Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000), Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000)]),\n",
       " Row(department=Row(id='456789', name='EE'), employees=[Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000), Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000)])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unionDF = df1.union(df3)\n",
    "unionDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(123456, CS)</td>\n",
       "      <td>[(erxiao, wang, xxx@berkekey.edu, 100000), (jh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(789012, ME)</td>\n",
       "      <td>[(tim, None, xxxx@cit.edu, 140000), (None, ng,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(234567, MM)</td>\n",
       "      <td>[(erxiao, wang, xxx@berkekey.edu, 100000), (No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(456789, EE)</td>\n",
       "      <td>[(jh, wang, xxxx@standord.edu, 120000), (tim, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     department                                          employees\n",
       "0  (123456, CS)  [(erxiao, wang, xxx@berkekey.edu, 100000), (jh...\n",
       "1  (789012, ME)  [(tim, None, xxxx@cit.edu, 140000), (None, ng,...\n",
       "2  (234567, MM)  [(erxiao, wang, xxx@berkekey.edu, 100000), (No...\n",
       "3  (456789, EE)  [(jh, wang, xxxx@standord.edu, 120000), (tim, ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unionDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wirte and read pyspark DF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unionDF.write.parquet('../data/uninDF.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetDF = sqlConctent.read.parquet('../data/uninDF.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(123456, CS)</td>\n",
       "      <td>[(erxiao, wang, xxx@berkekey.edu, 100000), (jh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(234567, MM)</td>\n",
       "      <td>[(erxiao, wang, xxx@berkekey.edu, 100000), (No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(456789, EE)</td>\n",
       "      <td>[(jh, wang, xxxx@standord.edu, 120000), (tim, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(789012, ME)</td>\n",
       "      <td>[(tim, None, xxxx@cit.edu, 140000), (None, ng,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     department                                          employees\n",
       "0  (123456, CS)  [(erxiao, wang, xxx@berkekey.edu, 100000), (jh...\n",
       "1  (234567, MM)  [(erxiao, wang, xxx@berkekey.edu, 100000), (No...\n",
       "2  (456789, EE)  [(jh, wang, xxxx@standord.edu, 120000), (tim, ...\n",
       "3  (789012, ME)  [(tim, None, xxxx@cit.edu, 140000), (None, ng,..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquetDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create spark's DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "eDF = sqlConctent.createDataFrame([sql.Row(a = 1, intlist=[1,2,3], mapfield={'a':'b'})])\n",
    "eDFx = sqlConctent.createDataFrame([sql.Row(a = 1, mapfield={'a':'b'}, intlist=[1,2,3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=1, intlist=[1, 2, 3], mapfield={'a': 'b'})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=1, intlist=[1, 2, 3], mapfield={'a': 'b'})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eDFx.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, anint: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eDF.select('a', explode(eDF.intlist).alias(\"anint\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[k: string, v: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eDF.select(explode(eDF.mapfield).alias(\"k\",\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parquetDF.select('department', explode('employees').alias('e'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(department=Row(id='123456', name='CS'), e=Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000)),\n",
       " Row(department=Row(id='123456', name='CS'), e=Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000)),\n",
       " Row(department=Row(id='234567', name='MM'), e=Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000)),\n",
       " Row(department=Row(id='234567', name='MM'), e=Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000)),\n",
       " Row(department=Row(id='456789', name='EE'), e=Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000)),\n",
       " Row(department=Row(id='456789', name='EE'), e=Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000)),\n",
       " Row(department=Row(id='789012', name='ME'), e=Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000)),\n",
       " Row(department=Row(id='789012', name='ME'), e=Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(s='abdc', d='123')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlConctent.createDataFrame([('abdc','123')], ['s','d'])\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(s='abdc123')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(concat(df.s, df.d).alias('s')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selectxpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000),\n",
       " Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000),\n",
       " Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000),\n",
       " Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parquetDF.select('department', explode('employees').alias('e'))\n",
    "explodeDF = df.selectExpr(\"e.firstName\",\"e.lastName\",\"e.email\",\"e.salary\")\n",
    "explodeDF.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterDF = explodeDF.filter(explodeDF.firstName == 'jh')\n",
    "filterDF.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000),\n",
       " Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000),\n",
       " Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000),\n",
       " Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000),\n",
       " Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explodeDF.sort(explodeDF.salary).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# col    asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000),\n",
       " Row(firstName='tim', lastName=None, email='xxxx@cit.edu', salary=140000)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explodeDF.filter((col('firstName')== 'jh')|(col('firstName')=='tim')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000),\n",
       " Row(firstName=None, lastName='ng', email='xxxx@mit.edu', salary=160000)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explodeDF.filter(col('firstName').isNull()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='erxiao', lastName='wang', email='xxx@berkekey.edu', salary=100000),\n",
       " Row(firstName='$$', lastName='ng', email='xxxx@mit.edu', salary=160000),\n",
       " Row(firstName='jh', lastName='wang', email='xxxx@standord.edu', salary=120000),\n",
       " Row(firstName='tim', lastName='$$', email='xxxx@cit.edu', salary=140000),\n",
       " Row(firstName='tim', lastName='$$', email='xxxx@cit.edu', salary=140000),\n",
       " Row(firstName='$$', lastName='ng', email='xxxx@mit.edu', salary=160000)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explodeDF.fillna('$$').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countDistinct, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstName=None, count(firstName)=0),\n",
       " Row(firstName='jh', count(firstName)=2),\n",
       " Row(firstName='tim', count(firstName)=2),\n",
       " Row(firstName='erxiao', count(firstName)=2)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countDistinctDF = explodeDF.select('firstName', 'lastName').groupby('firstName').agg(count('firstName'))\n",
    "countDistinctDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(DISTINCT firstName)=3)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explodeDF.select('firstName').agg(countDistinct('firstName')).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
