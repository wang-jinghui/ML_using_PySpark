{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Although it is used for classification, it's still called logistic regression .This is due to the linear regression equations still operate to find the relationship between input variable and the target variables. the main distinction between linear and logistic regression is that we use the some sort of nonlinear function to conver the output , and restrict it between 0 and 1.\n",
    "\n",
    "虽然它是用来分类的，但它仍然被称为逻辑回归，这是因为线性回归方程仍然可以找到输入变量和目标变量之间的关系。线性回归和逻辑回归的主要区别在于，我们使用某种非线性函数来转换输出，并将其限制在0和1之间。\n",
    "\n",
    "logisitc regression = nonlinear function(linear regression)\n",
    "\n",
    "linear regression : \n",
    "\n",
    "$$ y = b_0 + b_1 * x  $$\n",
    "\n",
    "nonlinear function:\n",
    "\n",
    "$$ \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "logistic regression :\n",
    "\n",
    "$$ Probability = \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "$$ Probability = \\frac{1}{1 + e^{-(b_0 + b_1 * x)}}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "- True Positives\n",
    "    - Actual calss: 1\n",
    "    - ML Model Prediction Class: 1\n",
    "- True Negatives\n",
    "    - Actual Class: 0\n",
    "    - ML Model Prediction Class: 0\n",
    "- False Positives\n",
    "    - Actual Class: 0\n",
    "    - ML Model Prediction Class: 1\n",
    "- False Negatives\n",
    "    - Actual Class: 1\n",
    "    - ML Model Prediction Class: 0\n",
    "    \n",
    "### Accuracy\n",
    "$$ \\frac{(TP + TN)}{Toatal number of records} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "$$\\frac{(TP)}{(TP + FN)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "$$\\frac{(TP)}{(TP + FP)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "$$ F1 Score = 2* \\frac{(Precision * Recall)}{(Precision +Recall)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "用来确定模型的阈值，平衡准确率和召回率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a logistic regression model\n",
    "\n",
    "- dataset : 20000行,6列。包含用户的国籍，年龄，使用的搜索引擎信息，浏览网页，是否回头客，等信息，预测顾客是否购买这一行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lg').getOrCreate()\n",
    "\n",
    "# load data\n",
    "df = spark.read.csv('./Data/Log_Reg_dataset.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Repeat_Visitor: integer (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Web_pages_viewed: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|  Country|Platform|\n",
      "+---------+--------+\n",
      "|    India|   Yahoo|\n",
      "|   Brazil|   Yahoo|\n",
      "|   Brazil|  Google|\n",
      "|Indonesia|    Bing|\n",
      "| Malaysia|  Google|\n",
      "+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Country', 'Platform').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+-----------------+------------------+\n",
      "|summary|              Age|   Repeat_Visitor| Web_pages_viewed|            Status|\n",
      "+-------+-----------------+-----------------+-----------------+------------------+\n",
      "|  count|            20000|            20000|            20000|             20000|\n",
      "|   mean|         28.53955|           0.5029|           9.5533|               0.5|\n",
      "| stddev|7.888912950773227|0.500004090187782|6.073903499824976|0.5000125004687693|\n",
      "|    min|               17|                0|                1|                 0|\n",
      "|    max|              111|                1|               29|                 1|\n",
      "+-------+-----------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Age', 'Repeat_Visitor', 'Web_pages_viewed', 'Status').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  Country|count|\n",
      "+---------+-----+\n",
      "| Malaysia| 1218|\n",
      "|    India| 4018|\n",
      "|Indonesia|12178|\n",
      "|   Brazil| 2586|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count  country\n",
    "df.groupBy('Country').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Platform|count|\n",
      "+--------+-----+\n",
      "|   Yahoo| 9859|\n",
      "|    Bing| 4360|\n",
      "|  Google| 5781|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Platform').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Repeat_Visitor|count|\n",
      "+--------------+-----+\n",
      "|             1|10058|\n",
      "|             0| 9942|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Repeat_Visitor').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Status|count|\n",
      "+------+-----+\n",
      "|     1|10000|\n",
      "|     0|10000|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Status').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|  Country|          avg(Age)|\n",
      "+---------+------------------+\n",
      "| Malaysia|27.792282430213465|\n",
      "|    India|27.976854156296664|\n",
      "|Indonesia| 28.43159796354081|\n",
      "|   Brazil|30.274168600154677|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Country', 'Age').groupBy('Country').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+---------------------+-----------+\n",
      "|Status|avg(Age)|avg(Repeat_Visitor)|avg(Web_pages_viewed)|avg(Status)|\n",
      "+------+--------+-------------------+---------------------+-----------+\n",
      "|     1| 26.5435|             0.7019|              14.5617|        1.0|\n",
      "|     0| 30.5356|             0.3039|               4.5449|        0.0|\n",
      "+------+--------+-------------------+---------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Age','Repeat_Visitor','Web_pages_viewed','Status').groupBy('Status').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "- 把categorical变量转换为数值\n",
    "- 把输入特征合并到一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------+--------+----------------+------+------------+\n",
      "|  Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Platform_num|\n",
      "+---------+---+--------------+--------+----------------+------+------------+\n",
      "|    India| 41|             1|   Yahoo|              21|     1|         0.0|\n",
      "|   Brazil| 28|             1|   Yahoo|               5|     0|         0.0|\n",
      "|   Brazil| 40|             0|  Google|               3|     0|         1.0|\n",
      "|Indonesia| 31|             1|    Bing|              15|     1|         2.0|\n",
      "| Malaysia| 32|             0|  Google|              15|     1|         1.0|\n",
      "+---------+---+--------------+--------+----------------+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# label encode\n",
    "platform_indexer = StringIndexer(inputCol='Platform', outputCol='Platform_num').fit(df)\n",
    "\n",
    "df = platform_indexer.transform(df)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "|Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Platform_num|platform_vector|\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "|  India| 41|             1|   Yahoo|              21|     1|         0.0|  (2,[0],[1.0])|\n",
      "| Brazil| 28|             1|   Yahoo|               5|     0|         0.0|  (2,[0],[1.0])|\n",
      "| Brazil| 40|             0|  Google|               3|     0|         1.0|  (2,[1],[1.0])|\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode\n",
    "platform_onehoter = OneHotEncoder(inputCol='Platform_num', outputCol='platform_vector')\n",
    "df = platform_onehoter.transform(df)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (2, [0], [1.0]) : 0, 1\n",
    "- (2, [1], [1.0]) : 1, 1\n",
    "- (2, [], []) : 0, 0\n",
    "- 这种表示，节省内存，计算更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+\n",
      "|Country|Country_Num|Country_vector|\n",
      "+-------+-----------+--------------+\n",
      "|India  |1.0        |(3,[1],[1.0]) |\n",
      "|Brazil |2.0        |(3,[2],[1.0]) |\n",
      "|Brazil |2.0        |(3,[2],[1.0]) |\n",
      "+-------+-----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# label encode country\n",
    "country_indexer = StringIndexer(inputCol='Country', outputCol='Country_num').fit(df)\n",
    "df = country_indexer.transform(df)\n",
    "# one-hot encode\n",
    "country_onehoter = OneHotEncoder(inputCol='Country_num', outputCol='Country_vector')\n",
    "df = country_onehoter.transform(df)\n",
    "df.select(['Country', 'Country_Num', 'Country_vector']).show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------+--------+----------------+------+------------+---------------+-----------+--------------+--------------------+\n",
      "|Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Platform_num|platform_vector|Country_num|Country_vector|            features|\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+-----------+--------------+--------------------+\n",
      "|  India| 41|             1|   Yahoo|              21|     1|         0.0|  (2,[0],[1.0])|        1.0| (3,[1],[1.0])|[1.0,0.0,0.0,1.0,...|\n",
      "| Brazil| 28|             1|   Yahoo|               5|     0|         0.0|  (2,[0],[1.0])|        2.0| (3,[2],[1.0])|[1.0,0.0,0.0,0.0,...|\n",
      "| Brazil| 40|             0|  Google|               3|     0|         1.0|  (2,[1],[1.0])|        2.0| (3,[2],[1.0])|(8,[1,4,5,7],[1.0...|\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+-----------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_assembler = VectorAssembler(inputCols=['platform_vector', 'Country_vector', 'Age', 'Repeat_Visitor', 'Web_pages_viewed'],\n",
    "                                                      outputCol='features')\n",
    "df = df_assembler.transform(df)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------+\n",
      "|features                           |Status|\n",
      "+-----------------------------------+------+\n",
      "|[1.0,0.0,0.0,1.0,0.0,41.0,1.0,21.0]|1     |\n",
      "|[1.0,0.0,0.0,0.0,1.0,28.0,1.0,5.0] |0     |\n",
      "|(8,[1,4,5,7],[1.0,1.0,40.0,3.0])   |0     |\n",
      "|(8,[2,5,6,7],[1.0,31.0,1.0,15.0])  |1     |\n",
      "|(8,[1,5,7],[1.0,32.0,15.0])        |1     |\n",
      "+-----------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['features', 'Status']).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_df shape : (15024 , 2)\n",
      " test_df  shape: :(4976 , 2)\n"
     ]
    }
   ],
   "source": [
    "data_set = df.select(['features', 'Status'])\n",
    "train_df, test_df = data_set.randomSplit([0.75, 0.25])\n",
    "print(' train_df shape : (%d , %d)'%(train_df.count(), len(train_df.columns)))\n",
    "print(' test_df  shape: :(%d , %d)'%(test_df.count(), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------------------------------+\n",
      "|Status|prediction|probability                             |\n",
      "+------+----------+----------------------------------------+\n",
      "|1     |1.0       |[0.2936888208146831,0.7063111791853168] |\n",
      "|1     |1.0       |[0.2936888208146831,0.7063111791853168] |\n",
      "|1     |1.0       |[0.16371245468320667,0.8362875453167934]|\n",
      "|1     |1.0       |[0.16371245468320667,0.8362875453167934]|\n",
      "|1     |1.0       |[0.16371245468320667,0.8362875453167934]|\n",
      "|1     |1.0       |[0.16371245468320667,0.8362875453167934]|\n",
      "|1     |1.0       |[0.08438651069737801,0.9156134893026219]|\n",
      "|1     |1.0       |[0.08438651069737801,0.9156134893026219]|\n",
      "|1     |1.0       |[0.08438651069737801,0.9156134893026219]|\n",
      "|1     |1.0       |[0.04158614711493927,0.9584138528850608]|\n",
      "+------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(labelCol = 'Status').fit(train_df)\n",
    "\n",
    "train_pred = log_reg.evaluate(train_df).predictions\n",
    "\n",
    "train_pred.filter(train_pred['Status'] == 1).filter(train_pred['prediction'] == 1).select(['Status', 'prediction', 'probability']).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|            features|Status|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|(8,[0,2,5,7],[1.0...|     0|[5.90239719539664...|[0.99727456260972...|       0.0|\n",
      "|(8,[0,2,5,7],[1.0...|     0|[5.90239719539664...|[0.99727456260972...|       0.0|\n",
      "|(8,[0,2,5,7],[1.0...|     0|[5.14907138147437...|[0.99422870848783...|       0.0|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result = log_reg.evaluate(test_df).predictions\n",
    "test_result.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "$$ Accuracy = \\frac{(TP + TN)}{(TP+FP+TN+FN)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is : 0.885116\n"
     ]
    }
   ],
   "source": [
    "tp = test_result[(test_result.Status == 1) & (test_result.prediction == 1)].count()\n",
    "tn = test_result[(test_result.Status == 0) & (test_result.prediction == 1)].count()\n",
    "fp = test_result[(test_result.Status == 0) & (test_result.prediction == 1)].count()\n",
    "fn = test_result[(test_result.Status == 1) & (test_result.prediction == 0)].count()\n",
    "# Accuracy\n",
    "\n",
    "print('test accuracy is : %f'%((tp+tn)/(tp+tn+fp+fn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test recall is : 0.934393\n",
      "test precision is : 0.935918\n"
     ]
    }
   ],
   "source": [
    "print('test recall is : %f'%(tp/(tp+fn)))\n",
    "print('test precision is : %f'%(tp/(tp+fp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
