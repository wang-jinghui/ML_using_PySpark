{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "* [Data set](#1)\n",
    "* [Create SparkSession and Load data](#2)\n",
    "* [EDA](#3)\n",
    "* [Feature Engineering](#4)\n",
    "* [Splitting Dataset](#5)\n",
    "* [Train Model](#6)\n",
    "* [Evaluation](#7)\n",
    "* [Recommend Movie](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='1'>Data set</h2>\n",
    "\n",
    "&emsp;&emsp;来自一个开源电影数据集，约10万条数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"2\">Create SparkSession and Load data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('RS').getOrCreate()\n",
    "\n",
    "# load dataset\n",
    "df = spark.read.csv('./Data/movie_ratings_df.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='3'>EDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------+\n",
      "|userId|       title|rating|\n",
      "+------+------------+------+\n",
      "|   196|Kolya (1996)|     3|\n",
      "|    63|Kolya (1996)|     3|\n",
      "|   226|Kolya (1996)|     5|\n",
      "|   154|Kolya (1996)|     3|\n",
      "|   306|Kolya (1996)|     5|\n",
      "|   296|Kolya (1996)|     4|\n",
      "|    34|Kolya (1996)|     5|\n",
      "|   271|Kolya (1996)|     4|\n",
      "|   201|Kolya (1996)|     4|\n",
      "|   209|Kolya (1996)|     4|\n",
      "+------+------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user recording\n",
    "userCount_df = df.groupBy('userId').count().orderBy('count', ascending=False)\n",
    "\n",
    "# Spark's DataFrame --> Pandas's DataFrame\n",
    "user_df = userCount_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>450</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  count\n",
       "0     405    737\n",
       "1     655    685\n",
       "2      13    636\n",
       "3     450    540\n",
       "4     276    518"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>242</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>571</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>873</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>475</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  count\n",
       "938     242     20\n",
       "939     571     20\n",
       "940     873     20\n",
       "941     475     20\n",
       "942      36     20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='4'>Feature Engineering</h2>\n",
    "\n",
    "- label encode\n",
    "     - Instance = stringIndexer(inputCol='xxx', outputCol='yyy')\n",
    "     - model = Instance.fit(df)\n",
    "     - new_df = model.transform(df)\n",
    "- reverse operation\n",
    "     - Instance = IndexToString(inputCol='yyy', outputCol='xxx', labels=model.labels)\n",
    "     - df = Instance.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------+---------+\n",
      "|userId|       title|rating|title_num|\n",
      "+------+------------+------+---------+\n",
      "|   196|Kolya (1996)|     3|    287.0|\n",
      "|    63|Kolya (1996)|     3|    287.0|\n",
      "|   226|Kolya (1996)|     5|    287.0|\n",
      "|   154|Kolya (1996)|     3|    287.0|\n",
      "|   306|Kolya (1996)|     5|    287.0|\n",
      "|   296|Kolya (1996)|     4|    287.0|\n",
      "|    34|Kolya (1996)|     5|    287.0|\n",
      "|   271|Kolya (1996)|     4|    287.0|\n",
      "|   201|Kolya (1996)|     4|    287.0|\n",
      "|   209|Kolya (1996)|     4|    287.0|\n",
      "+------+------------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexer = StringIndexer(inputCol='title', outputCol='title_num')\n",
    "\n",
    "model = stringIndexer.fit(df)\n",
    "\n",
    "new_df  = model.transform(df)\n",
    "\n",
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|title_num|count|\n",
      "+---------+-----+\n",
      "|      0.0|  583|\n",
      "|      1.0|  509|\n",
      "|      2.0|  508|\n",
      "|      3.0|  507|\n",
      "|      4.0|  485|\n",
      "|      5.0|  481|\n",
      "|      6.0|  478|\n",
      "|      7.0|  452|\n",
      "|      8.0|  431|\n",
      "|      9.0|  429|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.groupBy('title_num').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='5'> Splitting Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df, (69917, 4)\n",
      "test_df, (30083, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = new_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "print('train_df, (%d, %d)'%(train_df.count(), len(train_df.columns)))\n",
    "print('test_df, (%d, %d)'%(test_df.count(), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='6'> Train Model</h2>\n",
    "\n",
    "ALS\n",
    "- nonnegative='True', 没有分数为负值的评分\n",
    "- coldStartStrategy='drop',防止冷启动，分数为NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "rec = ALS(maxIter=10, regParam=0.01, userCol='userId', itemCol='title_num', ratingCol='rating', nonnegative=True,\n",
    "                 coldStartStrategy='drop')\n",
    "\n",
    "rs_model = rec.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='7'> Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+---------+\n",
      "|userId|               title|rating|title_num|\n",
      "+------+--------------------+------+---------+\n",
      "|     1|Apocalypse Now (1...|     3|     91.0|\n",
      "|     1|    Apollo 13 (1995)|     4|     51.0|\n",
      "|     1|Aristocats, The (...|     2|    575.0|\n",
      "|     1|Army of Darkness ...|     4|    289.0|\n",
      "+------+--------------------+------+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+---------+----------+\n",
      "|userId|               title|title_num|prediction|\n",
      "+------+--------------------+---------+----------+\n",
      "|   463|That Thing You Do...|    148.0| 2.5579684|\n",
      "|   251|That Thing You Do...|    148.0| 3.9390717|\n",
      "|   193|That Thing You Do...|    148.0|  3.070894|\n",
      "|   642|That Thing You Do...|    148.0| 3.9546824|\n",
      "|   101|That Thing You Do...|    148.0| 3.6771653|\n",
      "|   406|That Thing You Do...|    148.0| 3.0834832|\n",
      "|   731|That Thing You Do...|    148.0| 2.8964741|\n",
      "|   159|That Thing You Do...|    148.0|  5.029048|\n",
      "|   606|That Thing You Do...|    148.0| 3.6251612|\n",
      "|   336|That Thing You Do...|    148.0| 2.9238327|\n",
      "|   330|That Thing You Do...|    148.0| 4.2745767|\n",
      "|    93|That Thing You Do...|    148.0| 3.2026477|\n",
      "|   654|That Thing You Do...|    148.0| 4.2684965|\n",
      "|   152|That Thing You Do...|    148.0| 4.3452826|\n",
      "|   760|That Thing You Do...|    148.0|  4.768305|\n",
      "|   178|That Thing You Do...|    148.0| 4.1157365|\n",
      "|   839|That Thing You Do...|    148.0| 4.2218776|\n",
      "|   500|That Thing You Do...|    148.0| 2.9480288|\n",
      "|   432|That Thing You Do...|    148.0| 2.7699072|\n",
      "|   676|That Thing You Do...|    148.0| 2.6120367|\n",
      "+------+--------------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = test_df.select(['userId','title','title_num'])\n",
    "\n",
    "test_pred = rs_model.transform(test)\n",
    "\n",
    "test_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse is 1.036787\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "test_pred = rs_model.transform(test_df)\n",
    "\n",
    "evaluate_result = RegressionEvaluator(metricName='rmse', predictionCol='prediction', labelCol='rating')\n",
    "\n",
    "rmse = evaluate_result.evaluate(test_pred)\n",
    "\n",
    "print('test rmse is %f'%rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='8'>Recommend Movies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique_movies = new_df.select('title').distinct()\n",
    "\n",
    "nunique_movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total movies\n",
    "a = nunique_movies.alias('a')\n",
    "user_id = 66\n",
    "# user_id = 66，看过的电影\n",
    "watched_movies = new_df.filter(new_df['userId'] == user_id).select('title').distinct()\n",
    "b = watched_movies.alias('b')\n",
    "# a join b\n",
    "total_movies = a.join(b, a.title == b.title, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               title|               title|\n",
      "+--------------------+--------------------+\n",
      "|   Annie Hall (1977)|                null|\n",
      "|Heavenly Creature...|                null|\n",
      "|       Psycho (1960)|                null|\n",
      "|Snow White and th...|                null|\n",
      "|Night of the Livi...|                null|\n",
      "|When We Were King...|                null|\n",
      "| If Lucy Fell (1996)|                null|\n",
      "|    Fair Game (1995)|                null|\n",
      "| Three Wishes (1995)|                null|\n",
      "|         Cosi (1996)|                null|\n",
      "|Paris, France (1993)|                null|\n",
      "|Spanking the Monk...|                null|\n",
      "|I'll Do Anything ...|                null|\n",
      "|        Mondo (1996)|                null|\n",
      "| Evil Dead II (1987)|                null|\n",
      "|    Threesome (1994)|                null|\n",
      "|Last Action Hero ...|                null|\n",
      "|Reality Bites (1994)|                null|\n",
      "|Colonel Chabert, ...|                null|\n",
      "|   Blue Chips (1994)|                null|\n",
      "|A Chef in Love (1...|                null|\n",
      "|    Nico Icon (1995)|                null|\n",
      "|English Patient, ...|English Patient, ...|\n",
      "|Marvin's Room (1996)|                null|\n",
      "|Crows and Sparrow...|                null|\n",
      "+--------------------+--------------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_movies.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 66 没有看过的电影 1626\n"
     ]
    }
   ],
   "source": [
    "user_66_not_watched_movies = total_movies.where(col('b.title').isNull()).select(a.title).distinct()\n",
    "\n",
    "print('user 66 没有看过的电影 %d'%user_66_not_watched_movies.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------+\n",
      "|title                                 |userId|\n",
      "+--------------------------------------+------+\n",
      "|Annie Hall (1977)                     |66    |\n",
      "|Heavenly Creatures (1994)             |66    |\n",
      "|Psycho (1960)                         |66    |\n",
      "|Snow White and the Seven Dwarfs (1937)|66    |\n",
      "|Night of the Living Dead (1968)       |66    |\n",
      "|When We Were Kings (1996)             |66    |\n",
      "|If Lucy Fell (1996)                   |66    |\n",
      "|Fair Game (1995)                      |66    |\n",
      "|Three Wishes (1995)                   |66    |\n",
      "|Cosi (1996)                           |66    |\n",
      "+--------------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_66_not_watched_movies = user_66_not_watched_movies.withColumn('userId', lit(int(user_id)))\n",
    "\n",
    "user_66_not_watched_movies.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Recommend Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---------+----------+\n",
      "|               title|userId|title_num|prediction|\n",
      "+--------------------+------+---------+----------+\n",
      "|Ruby in Paradise ...|    66|    887.0|  6.453057|\n",
      "|Mis�rables, Les (...|    66|    911.0|  5.965375|\n",
      "| Apostle, The (1997)|    66|    572.0|  5.873897|\n",
      "|Miami Rhapsody (1...|    66|   1022.0| 5.8026986|\n",
      "|  Schizopolis (1996)|    66|   1372.0|  5.692012|\n",
      "|       Harlem (1993)|    66|   1369.0|  5.661992|\n",
      "|Mina Tannenbaum (...|    66|   1286.0|  5.637907|\n",
      "|In the Bleak Midw...|    66|    996.0|  5.628146|\n",
      "|Double vie de V�r...|    66|    904.0|  5.467951|\n",
      "|     Faithful (1996)|    66|   1129.0| 5.2826753|\n",
      "+--------------------+------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_66_df = model.transform(user_66_not_watched_movies)   # title >> title_num\n",
    "\n",
    "user_66_rs = rs_model.transform(user_66_df).orderBy('prediction', ascending=False)\n",
    "\n",
    "user_66_rs.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
